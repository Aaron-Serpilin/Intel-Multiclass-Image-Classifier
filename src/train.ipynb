{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train File\n",
    "This file's purpose is to train the model(s) to then prepare them for evaluation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.17.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/intel-image-classification.zip already exists. Skipping download.\n",
      "../data already exists and is not empty. Skipping extraction.\n",
      "There are 3 directories and 0 images in '../data/intel-image-classification'.\n",
      "There are 1 directories and 0 images in '../data/intel-image-classification/seg_test'.\n",
      "There are 6 directories and 0 images in '../data/intel-image-classification/seg_test/seg_test'.\n",
      "There are 0 directories and 474 images in '../data/intel-image-classification/seg_test/seg_test/forest'.\n",
      "There are 0 directories and 437 images in '../data/intel-image-classification/seg_test/seg_test/buildings'.\n",
      "There are 0 directories and 553 images in '../data/intel-image-classification/seg_test/seg_test/glacier'.\n",
      "There are 0 directories and 501 images in '../data/intel-image-classification/seg_test/seg_test/street'.\n",
      "There are 0 directories and 525 images in '../data/intel-image-classification/seg_test/seg_test/mountain'.\n",
      "There are 0 directories and 510 images in '../data/intel-image-classification/seg_test/seg_test/sea'.\n",
      "There are 1 directories and 0 images in '../data/intel-image-classification/seg_train'.\n",
      "There are 6 directories and 0 images in '../data/intel-image-classification/seg_train/seg_train'.\n",
      "There are 0 directories and 2271 images in '../data/intel-image-classification/seg_train/seg_train/forest'.\n",
      "There are 0 directories and 2191 images in '../data/intel-image-classification/seg_train/seg_train/buildings'.\n",
      "There are 0 directories and 2404 images in '../data/intel-image-classification/seg_train/seg_train/glacier'.\n",
      "There are 0 directories and 2382 images in '../data/intel-image-classification/seg_train/seg_train/street'.\n",
      "There are 0 directories and 2512 images in '../data/intel-image-classification/seg_train/seg_train/mountain'.\n",
      "There are 0 directories and 2274 images in '../data/intel-image-classification/seg_train/seg_train/sea'.\n",
      "There are 1 directories and 0 images in '../data/intel-image-classification/seg_pred'.\n",
      "There are 0 directories and 7301 images in '../data/intel-image-classification/seg_pred/seg_pred'.\n",
      "The relevant paths: train_dir: ../data/intel-image-classification/seg_train/seg_train\n",
      "test_dir: ../data/intel-image-classification/seg_test/seg_test\n",
      "image_path: ../data/intel-image-classification\n",
      "The img is: tensor([[[0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         ...,\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588]],\n",
      "\n",
      "        [[0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         ...,\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588]],\n",
      "\n",
      "        [[0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         ...,\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588]]])\n",
      "The shape is: torch.Size([3, 224, 224])\n",
      "The label is: 0\n",
      "Image shape: torch.Size([32, 3, 224, 224]) -> [batch_size, color_channels, height, width]\n",
      "Label shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "from importnb import Notebook\n",
    "with Notebook():\n",
    "    import dataloader, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all relevant variables\n",
    "BATCH_SIZE = model.BATCH_SIZE\n",
    "ResidualBlock = model.ResidualBlock\n",
    "RestNet = model.RestNet\n",
    "train_dataloader = dataloader.train_dataloader\n",
    "test_dataloader = dataloader.test_dataloader\n",
    "model_0 = model.model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step (model: torch.nn.Module,\n",
    "                data_loader: torch.utils.data.DataLoader,\n",
    "                loss_fn: torch.nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                accuracy_fn,\n",
    "                device: torch.device = device):\n",
    "    \n",
    "    train_loss, train_accuracy = 0, 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X) # Forward pass, outputs raw logits\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_accuracy += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)) # transforms from logits to labels\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # We adjust to get these metrics per batch, and not the total\n",
    "    train_loss /= len(data_loader)\n",
    "    train_accuracy /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_accuracy:.2f}%]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \n",
    "    test_loss, test_accuracy = 0, 0\n",
    "\n",
    "    model.eval()  # Turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers)\n",
    "\n",
    "    with torch.inference_mode(): # Turns off gradient tracking and a couple more things behind the scenes\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_pred_logits = model(X)\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            # test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            # test_accuracy += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "            test_accuracy += accuracy_fn(y_true=y, y_pred=test_pred_logits.argmax(dim=1)) # transforms from logits to labels\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_accuracy = test_accuracy / len(dataloader)\n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5,\n",
    "          device=device):\n",
    "\n",
    "  results = {\"train_loss\": [],\n",
    "             \"train_acc\": [],\n",
    "             \"test_loss\": [],\n",
    "             \"test_acc\": []}\n",
    "\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(model=model,\n",
    "                                       data_loader=train_dataloader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       accuracy_fn=accuracy_fn,\n",
    "                                       device=device)\n",
    "    test_loss, test_acc = test_step(model=model,\n",
    "                                    data_loader=test_dataloader,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    accuracy_fn=accuracy_fn,\n",
    "                                    device=device)\n",
    "\n",
    "    print(f\"Epoch: {epoch} | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
    "\n",
    "    results[\"train_loss\"].append(train_loss)\n",
    "    results[\"train_acc\"].append(train_acc)\n",
    "    results[\"test_loss\"].append(test_loss)\n",
    "    results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9c64a285694155a136ec8ab3532864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "model_0_results = train(model_0,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        device=device)\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
